{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8873df",
   "metadata": {},
   "source": [
    "# new 10.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e04cc0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.55.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers sentencepiece torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f24ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M.S.I\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "# atau untuk BERT2GPT:\n",
    "# from transformers import BertTokenizer, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6524743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pastikan sentencepiece sudah ada ---\n",
    "try:\n",
    "    import sentencepiece\n",
    "except ImportError:\n",
    "    os.system(\"pip install sentencepiece\")\n",
    "    import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f5a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M.S.I\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\M.S.I\\.cache\\huggingface\\hub\\models--panggi--t5-base-indonesian-summarization-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# --- Load model & tokenizer ---\n",
    "model_name = \"panggi/t5-base-indonesian-summarization-cased\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Jika pakai BERT2GPT:\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"cahya/bert2gpt-indonesian-summarization\")\n",
    "# tokenizer.bos_token = tokenizer.cls_token\n",
    "# tokenizer.eos_token = tokenizer.sep_token\n",
    "# model = EncoderDecoderModel.from_pretrained(\"cahya/bert2gpt-indonesian-summarization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ec9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baca teks dari file ---\n",
    "input_file = \"source-chatbot.txt\"\n",
    "if not os.path.exists(input_file):\n",
    "    raise FileNotFoundError(f\"File {input_file} tidak ditemukan!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bd94d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ce7d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info sebelum ringkas\n",
    "len_chars_before = len(text)\n",
    "len_words_before = len(text.split())\n",
    "min_words_target = int(len_words_before * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1ecf7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi meringkas satu chunk dengan minimal kata\n",
    "def summarize_chunk(chunk_text, min_words=1000, max_input_tokens=512):\n",
    "    # Estimasi max_output_tokens sesuai target kata\n",
    "    max_output_tokens = int(min_words * 1.3)  # tambahan buffer\n",
    "    input_ids = tokenizer.encode(chunk_text, return_tensors=\"pt\", truncation=True, max_length=max_input_tokens)\n",
    "    summary_ids = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_output_tokens,\n",
    "        min_length=min_words,\n",
    "        num_beams=4,\n",
    "        no_repeat_ngram_size=3,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pecah teks jadi beberapa bagian (per ~2000 kata)\n",
    "words = text.split()\n",
    "chunk_size = 2000\n",
    "chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86977535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung minimal kata per chunk\n",
    "min_words_per_chunk = int(chunk_size * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97566c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merangkum bagian 1/11...\n",
      "Merangkum bagian 2/11...\n",
      "Merangkum bagian 3/11...\n",
      "Merangkum bagian 4/11...\n",
      "Merangkum bagian 5/11...\n",
      "Merangkum bagian 6/11...\n",
      "Merangkum bagian 7/11...\n",
      "Merangkum bagian 8/11...\n",
      "Merangkum bagian 9/11...\n",
      "Merangkum bagian 10/11...\n",
      "Merangkum bagian 11/11...\n"
     ]
    }
   ],
   "source": [
    "# Ringkas tiap chunk & simpan\n",
    "all_summaries = []\n",
    "with open(\"summary_parts.txt\", \"w\", encoding=\"utf-8\") as f_parts:\n",
    "    for i, chunk in enumerate(chunks, start=1):\n",
    "        print(f\"Merangkum bagian {i}/{len(chunks)}...\")\n",
    "        summary_part = summarize_chunk(chunk, min_words=min_words_per_chunk)\n",
    "        all_summaries.append(summary_part)\n",
    "        f_parts.write(f\"--- Ringkasan Bagian {i} ---\\n{summary_part}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ac7e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan semua ringkasan chunk → hasil akhir\n",
    "final_summary = \"\\n\\n\".join(all_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7092eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info sesudah ringkas\n",
    "len_chars_after = len(final_summary)\n",
    "len_words_after = len(final_summary.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18a97e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Perbandingan Panjang Teks ===\n",
      "Sebelum: 149304 karakter, 20337 kata\n",
      "Sesudah: 35347 karakter, 5059 kata\n",
      "Target minimal: 10168 kata\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan info\n",
    "print(\"\\n=== Perbandingan Panjang Teks ===\")\n",
    "print(f\"Sebelum: {len_chars_before} karakter, {len_words_before} kata\")\n",
    "print(f\"Sesudah: {len_chars_after} karakter, {len_words_after} kata\")\n",
    "print(f\"Target minimal: {min_words_target} kata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ec35de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ringkasan berhasil disimpan!\n"
     ]
    }
   ],
   "source": [
    "# Simpan hasil\n",
    "with open(\"source-chatbot-short.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(final_summary)\n",
    "\n",
    "print(f\"\\nRingkasan berhasil disimpan!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c94000",
   "metadata": {},
   "source": [
    "# Google-Generative 11.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61f19c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06c22f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text_file(file_path, api_key, model=\"gemini-2.5-flash\", max_tokens=200):\n",
    "    # Inisialisasi klien dengan API key\n",
    "    client = genai.Client(api_key=api_key)\n",
    "    \n",
    "    # Baca isi file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    # Kirim permintaan generative AI untuk merangkum\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=text,\n",
    "        config=types.GenerateContentConfig(max_output_tokens=max_tokens)\n",
    "    )\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0559991",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"AIzaSyD1T_DQ4VTk8jKdtkcrHhZjTaXKT-0222s\")\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97947a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"source-chatbot.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36131b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung jumlah kata awal\n",
    "original_word_count = len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2d6f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt untuk membersihkan pengulangan, bukan merangkum pendek\n",
    "prompt = f\"\"\"\n",
    "Bersihkan teks berikut dari kalimat atau ide yang berulang, \n",
    "gabungkan kalimat yang mirip, dan pertahankan semua informasi penting, detail, dan data.\n",
    "Jangan hapus fakta penting. Jangan ringkas berlebihan.\n",
    "Teks:\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d42ba8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ab1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil hasil ringkasan\n",
    "summary = response.text.strip()\n",
    "\n",
    "# Hitung jumlah kata ringkasan\n",
    "summary_word_count = len(summary.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abc70b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah kata sebelum: 20337\n",
      "Jumlah kata sesudah: 2623\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan info jumlah kata\n",
    "print(f\"Jumlah kata sebelum: {original_word_count}\")\n",
    "print(f\"Jumlah kata sesudah: {summary_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49226ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hasil ringkasan berhasil disimpan ke: source-chatbot-short.txt\n"
     ]
    }
   ],
   "source": [
    "# Simpan hasil ringkasan ke file\n",
    "output_file = \"source-chatbot-short.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(f\"\\nHasil ringkasan berhasil disimpan ke: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba64c5c",
   "metadata": {},
   "source": [
    "# HYBRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7956a826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in c:\\users\\m.s.i\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (3.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8a6fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\M.S.I\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import google.generativeai as genai\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rapidfuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c970d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STEP 1: Deduplication Kasar ====\n",
    "def deduplicate_text(text, similarity_threshold=90):\n",
    "    sentences = sent_tokenize(text)\n",
    "    unique_sentences = []\n",
    "    for sentence in sentences:\n",
    "        clean_sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
    "        if not any(fuzz.ratio(clean_sentence, s) > similarity_threshold for s in unique_sentences):\n",
    "            unique_sentences.append(clean_sentence)\n",
    "    return \" \".join(unique_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45a3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_words=5000):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        chunk = \" \".join(words[i:i+max_words])\n",
    "        chunks.append(chunk)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648d34ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== STEP 2: Rapikan dengan Gemini ====\n",
    "# ===== Refine dengan Gemini =====\n",
    "def refine_with_gemini(text, api_key, model_name=\"gemini-1.5-flash\"):\n",
    "    genai.configure(api_key=api_key)\n",
    "    model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Rapikan teks berikut tanpa menghapus informasi penting.\n",
    "    Tugas Anda:\n",
    "    1. Gabungkan kalimat atau ide yang sama/serupa.\n",
    "    2. Hilangkan pengulangan kata/kalimat yang berlebihan.\n",
    "    3. Pertahankan semua fakta, angka, data, dan detail penting.\n",
    "    4. Jangan memendekkan teks secara signifikan.\n",
    "    5. Jaga agar hasil akhir tetap panjang, kaya informasi, dan enak dibaca.\n",
    "\n",
    "    Berikut teksnya:\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f5cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\M.S.I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\M.S.I\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"AIzaSyD1T_DQ4VTk8jKdtkcrHhZjTaXKT-0222s\"\n",
    "# input_file = \"source-chatbot.txt\"\n",
    "input_file = \"../bahan-chatbot/txt/rakornas_kemensos.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a734eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memproses chunk 1/2...\n",
      "Memproses chunk 2/2...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : bahan_ajar_groundchec_dtsen.txt\n",
      "Jumlah kata awal       : 6652\n",
      "Setelah dedup NLP      : 6607\n",
      "Setelah refine Gemini  : 1238\n",
      "Hasil akhir disimpan di: bahan_ajar_groundchec_dtsen-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : bahan_kemensos_panel.txt\n",
      "Jumlah kata awal       : 460\n",
      "Setelah dedup NLP      : 460\n",
      "Setelah refine Gemini  : 409\n",
      "Hasil akhir disimpan di: bahan_kemensos_panel-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : briefing_groundcheck_provinsi.txt\n",
      "Jumlah kata awal       : 1038\n",
      "Setelah dedup NLP      : 1039\n",
      "Setelah refine Gemini  : 577\n",
      "Hasil akhir disimpan di: briefing_groundcheck_provinsi-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : inpres_nomor_4_tahun_2025.txt\n",
      "Jumlah kata awal       : 1190\n",
      "Setelah dedup NLP      : 1183\n",
      "Setelah refine Gemini  : 705\n",
      "Hasil akhir disimpan di: inpres_nomor_4_tahun_2025-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : kesimpulan_rapat_koordinasi_nasional_penggunaan__dtsen_.txt\n",
      "Jumlah kata awal       : 355\n",
      "Setelah dedup NLP      : 355\n",
      "Setelah refine Gemini  : 254\n",
      "Hasil akhir disimpan di: kesimpulan_rapat_koordinasi_nasional_penggunaan__dtsen_-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : paparan_kebijakan_dtsen_rakornas.txt\n",
      "Jumlah kata awal       : 1387\n",
      "Setelah dedup NLP      : 1348\n",
      "Setelah refine Gemini  : 720\n",
      "Hasil akhir disimpan di: paparan_kebijakan_dtsen_rakornas-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : pemeringkatan_dtsen_kemensos.txt\n",
      "Jumlah kata awal       : 2737\n",
      "Setelah dedup NLP      : 2737\n",
      "Setelah refine Gemini  : 824\n",
      "Hasil akhir disimpan di: pemeringkatan_dtsen_kemensos-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n",
      "\n",
      "=== INFO HASIL ===\n",
      "File awal              : permensos_no_3_tahun_2025.txt\n",
      "Jumlah kata awal       : 3091\n",
      "Setelah dedup NLP      : 3039\n",
      "Setelah refine Gemini  : 1616\n",
      "Hasil akhir disimpan di: permensos_no_3_tahun_2025-short-hybrid.txt\n",
      "Memproses chunk 1/1...\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 50\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 12\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemproses chunk \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(chunks)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     refined_chunk \u001b[38;5;241m=\u001b[39m \u001b[43mrefine_with_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAPI_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     refined_chunks\u001b[38;5;241m.\u001b[39mappend(refined_chunk)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Step 4: Gabungkan hasil\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 20\u001b[0m, in \u001b[0;36mrefine_with_gemini\u001b[1;34m(text, api_key, model_name)\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(model_name)\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mRapikan teks berikut tanpa menghapus informasi penting.\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mTugas Anda:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    210\u001b[0m         error_list,\n\u001b[0;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    212\u001b[0m         original_timeout,\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-1.5-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 50\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 12\n}\n]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "folder_path = \"../bahan-chatbot/txt/\"\n",
    "\n",
    "# Loop semua file di folder ../txt/\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):  # cuma file txt\n",
    "        input_file = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Baca file asli\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            original_text = f.read()\n",
    "\n",
    "        # Baca file asli\n",
    "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            original_text = f.read()\n",
    "\n",
    "        # Hitung kata awal\n",
    "        original_count = len(original_text.split())\n",
    "\n",
    "        # Step 1: Deduplication NLP\n",
    "        dedup_text = deduplicate_text(original_text)\n",
    "        dedup_count = len(dedup_text.split())\n",
    "\n",
    "        # Step 2: Chunking\n",
    "        chunks = chunk_text(dedup_text, max_words=5000)\n",
    "\n",
    "        # Step 3: Refine tiap chunk\n",
    "        refined_chunks = []\n",
    "        for idx, chunk in enumerate(chunks, 1):\n",
    "            print(f\"Memproses chunk {idx}/{len(chunks)}...\")\n",
    "            refined_chunk = refine_with_gemini(chunk, API_KEY)\n",
    "            refined_chunks.append(refined_chunk)\n",
    "\n",
    "        # Step 4: Gabungkan hasil\n",
    "        final_text = \"\\n\\n\".join(refined_chunks)\n",
    "        final_count = len(final_text.split())\n",
    "\n",
    "        # Simpan hasil akhir\n",
    "        name_only, ext = os.path.splitext(filename)  # name_only = \"contoh\", ext = \".txt\"\n",
    "        output_file = name_only + \"-short-hybrid.txt\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(final_text)\n",
    "\n",
    "        # Info hasil\n",
    "        print(\"\\n=== INFO HASIL ===\")\n",
    "        print(f\"File awal              : {filename}\")\n",
    "        print(f\"Jumlah kata awal       : {original_count}\")\n",
    "        print(f\"Setelah dedup NLP      : {dedup_count}\")\n",
    "        print(f\"Setelah refine Gemini  : {final_count}\")\n",
    "        print(f\"Hasil akhir disimpan di: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241fb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== MAIN PROGRAM ====\n",
    "if __name__ == \"__main__\":\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    API_KEY = \"YOUR_API_KEY\"\n",
    "    input_file = \"file.txt\"\n",
    "\n",
    "    # Baca file asli\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        original_text = f.read()\n",
    "\n",
    "    # Hitung kata awal\n",
    "    original_count = len(original_text.split())\n",
    "\n",
    "    # Step 1: Deduplication NLP\n",
    "    dedup_text = deduplicate_text(original_text)\n",
    "    dedup_count = len(dedup_text.split())\n",
    "\n",
    "    # Step 2: Refine dengan Gemini\n",
    "    refined_text = refine_with_gemini(dedup_text, API_KEY)\n",
    "    refined_count = len(refined_text.split())\n",
    "\n",
    "    # Simpan hasil akhir\n",
    "    output_file = \"file_bersih.txt\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(refined_text)\n",
    "\n",
    "    # Info hasil\n",
    "    print(f\"Jumlah kata awal       : {original_count}\")\n",
    "    print(f\"Setelah dedup NLP      : {dedup_count}\")\n",
    "    print(f\"Setelah refine Gemini  : {refined_count}\")\n",
    "    print(f\"Hasil akhir disimpan di: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
